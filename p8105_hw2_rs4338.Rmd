---
title: "p8105_hw2_rs4338"
author: "Rebecca Shyu"
date: "2024-09-28"
output: github_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
```

## Problem 0:

* Create a public GitHub repo + local R Project: p8105_hw2_rs4338
* Create a single .Rmd file named p8105_hw2_rs4338.Rmd that renders to github_document
* Create a subdirectory (data) to store the local data files, and use relative paths to access these data files
* Submit a link to your repo via Courseworks
  - https://github.com/rysgpd/p8105_hw2_rs4338

## Problem 1:

* Reading & Cleaning the Dataset
  - Before processing, there were 32 variables and 1,868 rows included in the dataset. It looks like each row is an entrance and/or exit to a station, so there can be many rows for a single station. It provides information about the location (longitude/latitude of both entrance/exit and station) and characteristics (ex: ADA accessible, vending, staffing, etc) of the entrance/exit. There are also up to 11 routes that may stop at the station. 
  - Some data cleaning steps I took were: cleaning names using the `janitor` package,  converted route8 to route11 to `character` when reading in the csv file, selecting the variables outlined in the homework assignment (line, station, name, station latitude / longitude, routes served, entrance type, entry, vending, and ADA compliance) through the `select` function, changed the entry and vending variables from YES/NO to 0/1 from the instructions through the `mutate` function.
  - The dimensions of the resulting table are 19 variables/columns and 1,868 rows/entrances/exits.
  - The data is tidy because the columns are variable names not values, each column has multiple variables, and there is only one table.

```{r prob1_readcsv, message=FALSE}
initial_nyc_transit_df= read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") 

nyc_transit_df = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                          col_types = cols(
                            Route8 = "c",
                            Route9 = "c",
                            Route10 = "c",
                            Route11 = "c",
                            )
                          ) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = ifelse(entry == "YES", 1, 0),
    vending = ifelse(vending == "YES", 1, 0)
  )

nyc_transit_df
```

* Answer the following questions:
  - There are 465 distinct stations (using the `distinct` function)
  - There are 84 distinct stations that are ADA-compliant. 
  - The proportion of station entrances/exits w/o vending that allow entrance is 0.3770492.
  - Reformatting the data using the `unite` function, there are 
  
  How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?


```{r probl1_questions, collapse = TRUE}

nyc_transit_df %>% 
  distinct(line, station_name) %>% 
  count()

nyc_transit_df %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(ada == TRUE) %>% 
  count()

no_vending_num = 
  nyc_transit_df %>% 
  filter(
    vending == 0
    ) %>% 
  count()

no_vending_yes_entry =
  nyc_transit_df %>% 
  filter(
    vending == 0,
    entry == 1
  ) %>% 
  count()

no_vending_yes_entry/no_vending_num

    
```

## Problem 2:

* Read and clean the Mr. Trash Wheel datasets to produce a single tidy dataset (trash_df)
* The final tidy dataset is comprised of 845 total observations with 584 from Mr. Trash Wheel, 106 from Professor Trash Wheel, and 155 from Gwynnda. The data spanned from 2014 to 2023 and included specific dates that the trash was collected. The dataset also includes the weight (tons) that ranged from 0.61 to 5.62, volume (cubic yards) that ranged from 5 to 20, and the number of pollutant objects found. These included plastic bottles, polystyrene, cigarette butts, glass bottles, plastic bags, wrappers, and sports balls. Almost all of the objects were counted for each dumpster check, except there were 156 missing for glass bottles, 118 for wrappers, and 261 for sports balls. The object with the largest mean among all dumpsters was cigarette butts at 15,592. The dataset also calculated the estimated number of homes powered by the collected trash.
* The total weight of trash collected by Professor Trash Wheel was 1875.1	tons.
* The total number of cigarette butts collected by Gwynnda in June 2022 was 18,120.


```{r prob2, collapse=TRUE}

mr_trash_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range="A2:N586") %>% 
  janitor::clean_names() %>% 
  mutate(
    sports_balls = round(sports_balls, digits = 0),
    sports_balls = as.integer(sports_balls),
    year = as.double(year),
    wheel = "mr_trash"
  )

prof_trash_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range="A2:M108") %>% 
  janitor::clean_names() %>% 
  mutate(
    wheel = "prof_trash"
  )

gwynnda_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range="A2:L157") %>% 
  janitor::clean_names()%>% 
  mutate(
    wheel = "gwynnda"
  )

trash_df = 
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_df) %>% 
  relocate(wheel)
  
summary(trash_df)

trash_df %>% 
  filter(
    wheel == "mr_trash"
  ) %>% 
  summarise(sum(weight_tons, na.rm=TRUE))

trash_df %>% 
  filter(
    wheel == "gwynnda",
    year == 2022,
    month == "June"
  ) %>% 
  summarise(sum(cigarette_butts, na.rm=TRUE))
```

## Problem 3:

```{r prob3}

gbbo_bakers = read_csv("data/gbb_datasets/bakers.csv") %>% 
  janitor::clean_names() %>% 
  separate(baker_name, c("baker_first_name", "baker_last_name"), sep=" ")

gbbo_bakes = read_csv("data/gbb_datasets/bakes.csv",
                      na=c("N/A", "NA", "UNKNOWN","", "Unknown")) %>% 
  janitor::clean_names()

gbbo_results = read_csv("data/gbb_datasets/results.csv",
                        skip = 2) %>% 
  janitor::clean_names()

gbbo_viewers = read_csv("data/gbb_datasets/viewers.csv") %>% 
  janitor::clean_names()

```

